# 计算bert_score的代码
# Include necessary packages (torch, spacy, ...)
from selfcheckgpt.modeling_selfcheck import SelfCheckMQAG, SelfCheckBERTScore, SelfCheckNgram
import spacy
import argparse
import os
import json
import math
from tqdm import tqdm
nlp = spacy.load('en_core_web_sm')
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# selfcheck_mqag = SelfCheckMQAG(device=device) # set device to 'cuda' if GPU is available
selfcheck_bertscore = SelfCheckBERTScore(rescale_with_baseline=True)
# selfcheck_ngram = SelfCheckNgram(n=1) # n=1 means Unigram, n=2 means Bigram, etc.

# LLM's text (e.g. GPT-3 response) to be evaluated at the sentence level  & Split it into sentences
# passage = "Michael Alan Weiner (born March 31, 1942) is an American radio host. He is the host of The Savage Nation."
# sentences = [sent.text.strip() for sent in nlp(passage).sents] # spacy sentence tokenization
# print(sentences)
# ['Michael Alan Weiner (born March 31, 1942) is an American radio host.', 'He is the host of The Savage Nation.']

# # Other samples generated by the same LLM to perform self-check for consistency
# sample1 = "Michael Alan Weiner (born March 31, 1942) is an American radio host. He is the host of The Savage Country."
# sample2 = "Michael Alan Weiner (born January 13, 1960) is a Canadian radio host. He works at The New York Times."
# sample3 = "Michael Alan Weiner (born March 31, 1942) is an American radio host. He obtained his PhD from MIT."
import time





print(">>>>>>>>>>>>>>>FINISHED<<<<<<<<<<<<<<<<<")
def parse_args():
    parser = argparse.ArgumentParser(description="Evaluation")
    parser.add_argument("--input_file", type=str, required=True)
    parser.add_argument("--gpu_id", type=int, default=7)
    args = parser.parse_args()
    return args
# import pdb;pdb.set_trace()



args = parse_args()
input_file = args.input_file
device = "cuda:{}".format(args.gpu_id)
# import pdb;pdb.set_trace()
output_file_name = os.path.basename(input_file)
output_file = os.path.join(args.input_file,"minigpt4")
output_file = output_file.replace("selfcheck","bert_score")
# import pdb;pdb.set_trace()
output_file = output_file.split('.json')[0] + '_bert_score.jsonl'
# import pdb;pdb.set_trace()
print(output_file)
# output_file ="/data/huangtao/projects/llm-safty/MyVLMTest/uncertainty/selfcheck_results/minigpt4/minigpt4-red_team1k-red_team1k-with_image-2023102811bert_score.jsonl"
def float_it(score):
    for key in score.keys():
        score[key] = float(score[key])
    return score

# aim_dict = {'bert_score": [0.6522657871246338, 0.6498339027166367, 0.6565408036112785, 0.586967721581459, 0.7668504193425179, 0.6624917268753052]}


inputs = open(input_file).read().strip().split('\n')
# import pdb;pdb.set_trace()
with open(output_file, 'a') as f:
    flag = 1
    for li in tqdm(inputs,ncols=180,position=0 ,leave=True):
        obj = json.loads(li)
        # if obj['image_id'] != "259.png" and flag == 1:
        #     continue
        flag = 0
        # import pdb;pdb.set_trace()
        if 'continuation' in obj and obj['continuation'] != "":
            # import pdb;pdb.set_trace()
            passage = obj['continuation']
            sentences = [sent.text.strip() for sent in nlp(passage).sents] # spacy sentence tokenization

            print(obj["continuation"])
            sent_scores_bertscore = selfcheck_bertscore.predict(sentences = sentences,sampled_passages = obj["stochastic_response"])
            sent_scores_bertscore = list(sent_scores_bertscore)
            sent_scores_bertscore.append(sum(sent_scores_bertscore)/len(sent_scores_bertscore))
            obj['bert_score'] = sent_scores_bertscore
            # import pdb;pdb.set_trace()


            f.write(json.dumps(obj))
            f.write('\n')
        # f.close()
